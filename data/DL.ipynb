{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.vocab import GloVe\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import pandas as pd\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in training data: 1306122\n",
      "Number of data points in test data: 375806\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('./train.csv')\n",
    "df_test = pd.read_csv('./test.csv')\n",
    "\n",
    "print(\"Number of data points in training data:\", df_train.shape[0])\n",
    "print(\"Number of data points in test data:\", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing math equations and url addresses with tags.\n",
    "def clean_tag(x):\n",
    "  if '[math]' in x:\n",
    "    x = re.sub('\\[math\\].*?math\\]', 'MATH EQUATION', x) #replacing with [MATH EQUATION]\n",
    "    \n",
    "  if 'http' in x or 'www' in x:\n",
    "    x = re.sub('(?:(?:https?|ftp):\\/\\/)?[\\w/\\-?=%.]+\\.[\\w/\\-?=%.]+', 'URL', x) #replacing with [url]\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', \n",
    "        '•', '~', '@', '£', '·', '_', '{', '}', '©', '^', '®', '`', '<', '→', '°', '€', '™', '›', '♥', '←', '×', '§', '″', '′', \n",
    "        '█', '…', '“', '★', '”', '–', '●', '►', '−', '¢', '¬', '░', '¡', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', \n",
    "        '—', '‹', '─', '▒', '：', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', '¯', '♦', '¤', '▲', '¸', '⋅', '‘', '∞', \n",
    "        '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '・', '╦', '╣', '╔', '╗', '▬', '❤', '≤', '‡', '√', '◄', '━', \n",
    "        '⇒', '▶', '≥', '╝', '♡', '◊', '。', '✈', '≡', '☺', '✔', '↵', '≈', '✓', '♣', '☎', '℃', '◦', '└', '‟', '～', '！', '○', \n",
    "        '◆', '№', '♠', '▌', '✿', '▸', '⁄', '□', '❖', '✦', '．', '÷', '｜', '┃', '／', '￥', '╠', '↩', '✭', '▐', '☼', '☻', '┐', \n",
    "        '├', '«', '∼', '┌', '℉', '☮', '฿', '≦', '♬', '✧', '〉', '－', '⌂', '✖', '･', '◕', '※', '‖', '◀', '‰', '\\x97', '↺', \n",
    "        '∆', '┘', '┬', '╬', '،', '⌘', '⊂', '＞', '〈', '⎙', '？', '☠', '⇐', '▫', '∗', '∈', '≠', '♀', '♔', '˚', '℗', '┗', '＊', \n",
    "        '┼', '❀', '＆', '∩', '♂', '‿', '∑', '‣', '➜', '┛', '⇓', '☯', '⊖', '☀', '┳', '；', '∇', '⇑', '✰', '◇', '♯', '☞', '´', \n",
    "        '↔', '┏', '｡', '◘', '∂', '✌', '♭', '┣', '┴', '┓', '✨', '\\xa0', '˜', '❥', '┫', '℠', '✒', '［', '∫', '\\x93', '≧', '］', \n",
    "        '\\x94', '∀', '♛', '\\x96', '∨', '◎', '↻', '⇩', '＜', '≫', '✩', '✪', '♕', '؟', '₤', '☛', '╮', '␊', '＋', '┈', '％', \n",
    "        '╋', '▽', '⇨', '┻', '⊗', '￡', '।', '▂', '✯', '▇', '＿', '➤', '✞', '＝', '▷', '△', '◙', '▅', '✝', '∧', '␉', '☭', \n",
    "        '┊', '╯', '☾', '➔', '∴', '\\x92', '▃', '↳', '＾', '׳', '➢', '╭', '➡', '＠', '⊙', '☢', '˝', '∏', '„', '∥', '❝', '☐', \n",
    "        '▆', '╱', '⋙', '๏', '☁', '⇔', '▔', '\\x91', '➚', '◡', '╰', '\\x85', '♢', '˙', '۞', '✘', '✮', '☑', '⋆', 'ⓘ', '❒', \n",
    "        '☣', '✉', '⌊', '➠', '∣', '❑', '◢', 'ⓒ', '\\x80', '〒', '∕', '▮', '⦿', '✫', '✚', '⋯', '♩', '☂', '❞', '‗', '܂', '☜', \n",
    "        '‾', '✜', '╲', '∘', '⟩', '＼', '⟨', '·', '✗', '♚', '∅', 'ⓔ', '◣', '͡', '‛', '❦', '◠', '✄', '❄', '∃', '␣', '≪', '｢', \n",
    "        '≅', '◯', '☽', '∎', '｣', '❧', '̅', 'ⓐ', '↘', '⚓', '▣', '˘', '∪', '⇢', '✍', '⊥', '＃', '⎯', '↠', '۩', '☰', '◥', \n",
    "        '⊆', '✽', '⚡', '↪', '❁', '☹', '◼', '☃', '◤', '❏', 'ⓢ', '⊱', '➝', '̣', '✡', '∠', '｀', '▴', '┤', '∝', '♏', 'ⓐ', \n",
    "        '✎', ';', '␤', '＇', '❣', '✂', '✤', 'ⓞ', '☪', '✴', '⌒', '˛', '♒', '＄', '✶', '▻', 'ⓔ', '◌', '◈', '❚', '❂', '￦', \n",
    "        '◉', '╜', '̃', '✱', '╖', '❉', 'ⓡ', '↗', 'ⓣ', '♻', '➽', '׀', '✲', '✬', '☉', '▉', '≒', '☥', '⌐', '♨', '✕', 'ⓝ', \n",
    "        '⊰', '❘', '＂', '⇧', '̵', '➪', '▁', '▏', '⊃', 'ⓛ', '‚', '♰', '́', '✏', '⏑', '̶', 'ⓢ', '⩾', '￠', '❍', '≃', '⋰', '♋', \n",
    "        '､', '̂', '❋', '✳', 'ⓤ', '╤', '▕', '⌣', '✸', '℮', '⁺', '▨', '╨', 'ⓥ', '♈', '❃', '☝', '✻', '⊇', '≻', '♘', '♞', \n",
    "        '◂', '✟', '⌠', '✠', '☚', '✥', '❊', 'ⓒ', '⌈', '❅', 'ⓡ', '♧', 'ⓞ', '▭', '❱', 'ⓣ', '∟', '☕', '♺', '∵', '⍝', 'ⓑ', \n",
    "        '✵', '✣', '٭', '♆', 'ⓘ', '∶', '⚜', '◞', '்', '✹', '➥', '↕', '̳', '∷', '✋', '➧', '∋', '̿', 'ͧ', '┅', '⥤', '⬆', '⋱', \n",
    "        '☄', '↖', '⋮', '۔', '♌', 'ⓛ', '╕', '♓', '❯', '♍', '▋', '✺', '⭐', '✾', '♊', '➣', '▿', 'ⓑ', '♉', '⏠', '◾', '▹', \n",
    "        '⩽', '↦', '╥', '⍵', '⌋', '։', '➨', '∮', '⇥', 'ⓗ', 'ⓓ', '⁻', '⎝', '⌥', '⌉', '◔', '◑', '✼', '♎', '♐', '╪', '⊚', \n",
    "        '☒', '⇤', 'ⓜ', '⎠', '◐', '⚠', '╞', '◗', '⎕', 'ⓨ', '☟', 'ⓟ', '♟', '❈', '↬', 'ⓓ', '◻', '♮', '❙', '♤', '∉', '؛', \n",
    "        '⁂', 'ⓝ', '־', '♑', '╫', '╓', '╳', '⬅', '☔', '☸', '┄', '╧', '׃', '⎢', '❆', '⋄', '⚫', '̏', '☏', '➞', '͂', '␙', \n",
    "        'ⓤ', '◟', '̊', '⚐', '✙', '↙', '̾', '℘', '✷', '⍺', '❌', '⊢', '▵', '✅', 'ⓖ', '☨', '▰', '╡', 'ⓜ', '☤', '∽', '╘', \n",
    "        '˹', '↨', '♙', '⬇', '♱', '⌡', '⠀', '╛', '❕', '┉', 'ⓟ', '̀', '♖', 'ⓚ', '┆', '⎜', '◜', '⚾', '⤴', '✇', '╟', '⎛', \n",
    "        '☩', '➲', '➟', 'ⓥ', 'ⓗ', '⏝', '◃', '╢', '↯', '✆', '˃', '⍴', '❇', '⚽', '╒', '̸', '♜', '☓', '➳', '⇄', '☬', '⚑', \n",
    "        '✐', '⌃', '◅', '▢', '❐', '∊', '☈', '॥', '⎮', '▩', 'ு', '⊹', '‵', '␔', '☊', '➸', '̌', '☿', '⇉', '⊳', '╙', 'ⓦ', \n",
    "        '⇣', '｛', '̄', '↝', '⎟', '▍', '❗', '״', '΄', '▞', '◁', '⛄', '⇝', '⎪', '♁', '⇠', '☇', '✊', 'ி', '｝', '⭕', '➘', \n",
    "        '⁀', '☙', '❛', '❓', '⟲', '⇀', '≲', 'ⓕ', '⎥', '\\u06dd', 'ͤ', '₋', '̱', '̎', '♝', '≳', '▙', '➭', '܀', 'ⓖ', '⇛', '▊', \n",
    "        '⇗', '̷', '⇱', '℅', 'ⓧ', '⚛', '̐', '̕', '⇌', '␀', '≌', 'ⓦ', '⊤', '̓', '☦', 'ⓕ', '▜', '➙', 'ⓨ', '⌨', '◮', '☷', \n",
    "        '◍', 'ⓚ', '≔', '⏩', '⍳', '℞', '┋', '˻', '▚', '≺', 'ْ', '▟', '➻', '̪', '⏪', '̉', '⎞', '┇', '⍟', '⇪', '▎', '⇦', '␝', \n",
    "        '⤷', '≖', '⟶', '♗', '̴', '♄', 'ͨ', '̈', '❜', '̡', '▛', '✁', '➩', 'ா', '˂', '↥', '⏎', '⎷', '̲', '➖', '↲', '⩵', '̗', '❢', \n",
    "        '≎', '⚔', '⇇', '̑', '⊿', '̖', '☍', '➹', '⥊', '⁁', '✢']\n",
    "\n",
    "def clean_punct(x):\n",
    "  x = str(x)\n",
    "  for punct in puncts:\n",
    "    if punct in x:\n",
    "      x = x.replace(punct, ' ')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "def remove_stopwords(x):\n",
    "  x = [word for word in x.split() if word not in STOPWORDS]\n",
    "  x = ' '.join(x)\n",
    "\n",
    "  return x\n",
    "\n",
    "# word lemmatizing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemma_text(x):\n",
    "  x = x.split()\n",
    "  x = [lemmatizer.lemmatize(word) for word in x]\n",
    "  x = ' '.join(x)\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(x):\n",
    "  x = clean_tag(x)\n",
    "  x = clean_punct(x)\n",
    "  x = remove_stopwords(x)\n",
    "  x = lemma_text(x)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing given train and test data\n",
    "df_train['preprocessed_question_text'] = df_train['question_text'].map(lambda x: data_cleaning(x))\n",
    "df_test['preprocessed_question_text'] = df_test['question_text'].map(lambda x: data_cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>preprocessed_question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arroga...</td>\n",
       "      <td>Why many woman become rude arrogant little bit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineer...</td>\n",
       "      <td>When I apply RV college engineering BMS colleg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitio...</td>\n",
       "      <td>What really nurse practitioner?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "      <td>Who entrepreneurs?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375801</th>\n",
       "      <td>ffff7fa746bd6d6197a9</td>\n",
       "      <td>How many countries listed in gold import in in...</td>\n",
       "      <td>How many country listed gold import indua?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375802</th>\n",
       "      <td>ffffa1be31c43046ab6b</td>\n",
       "      <td>Is there an alternative to dresses on formal p...</td>\n",
       "      <td>Is alternative dress formal parties?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375803</th>\n",
       "      <td>ffffae173b6ca6bfa563</td>\n",
       "      <td>Where I can find best friendship quotes in Tel...</td>\n",
       "      <td>Where I find best friendship quote Telugu?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375804</th>\n",
       "      <td>ffffb1f7f1a008620287</td>\n",
       "      <td>What are the causes of refraction of light?</td>\n",
       "      <td>What cause refraction light?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375805</th>\n",
       "      <td>fffff85473f4699474b0</td>\n",
       "      <td>Climate change is a worrying topic. How much t...</td>\n",
       "      <td>Climate change worrying topic. How much time l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375806 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "0       0000163e3ea7c7a74cd7   \n",
       "1       00002bd4fb5d505b9161   \n",
       "2       00007756b4a147d2b0b3   \n",
       "3       000086e4b7e1c7146103   \n",
       "4       0000c4c3fbe8785a3090   \n",
       "...                      ...   \n",
       "375801  ffff7fa746bd6d6197a9   \n",
       "375802  ffffa1be31c43046ab6b   \n",
       "375803  ffffae173b6ca6bfa563   \n",
       "375804  ffffb1f7f1a008620287   \n",
       "375805  fffff85473f4699474b0   \n",
       "\n",
       "                                            question_text  \\\n",
       "0       Why do so many women become so rude and arroga...   \n",
       "1       When should I apply for RV college of engineer...   \n",
       "2       What is it really like to be a nurse practitio...   \n",
       "3                                  Who are entrepreneurs?   \n",
       "4        Is education really making good people nowadays?   \n",
       "...                                                   ...   \n",
       "375801  How many countries listed in gold import in in...   \n",
       "375802  Is there an alternative to dresses on formal p...   \n",
       "375803  Where I can find best friendship quotes in Tel...   \n",
       "375804        What are the causes of refraction of light?   \n",
       "375805  Climate change is a worrying topic. How much t...   \n",
       "\n",
       "                               preprocessed_question_text  \n",
       "0       Why many woman become rude arrogant little bit...  \n",
       "1       When I apply RV college engineering BMS colleg...  \n",
       "2                         What really nurse practitioner?  \n",
       "3                                      Who entrepreneurs?  \n",
       "4        Is education really making good people nowadays?  \n",
       "...                                                   ...  \n",
       "375801         How many country listed gold import indua?  \n",
       "375802               Is alternative dress formal parties?  \n",
       "375803         Where I find best friendship quote Telugu?  \n",
       "375804                       What cause refraction light?  \n",
       "375805  Climate change worrying topic. How much time l...  \n",
       "\n",
       "[375806 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into features (text) and labels\n",
    "X = df_train['preprocessed_question_text']\n",
    "y = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [word for sentence in X for word in sentence.split()]\n",
    "\n",
    "# Count unique tokens\n",
    "vocabulary_size = len(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461951"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# Tokenization function\n",
    "def vectorize(text):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    input_sequence = pad_sequences(sequences,maxlen = 20, padding = 'pre', truncating = 'post')\n",
    "    return input_sequence\n",
    "# in this case scemantic meaning is not captured, the words are just represented by their index in the vocabulary list (scalar)\n",
    "# To capture the scemantic meaning we need to convert into word embeddings which can be trained for a particular corpus or can be derived using pretrained \n",
    "# word embeddings  \n",
    "# Tokenize the text data\n",
    "X_train_padded = vectorize(X_train)\n",
    "X_val_padded = vectorize(X_val)\n",
    "X_test_padded = vectorize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Convert Pandas Series to NumPy arrays\n",
    "y_train_np = y_train.to_numpy()\n",
    "y_val_np = y_val.to_numpy()\n",
    "y_test_np = y_test.to_numpy()\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "y_train_tensor = torch.LongTensor(y_train_np)\n",
    "y_val_tensor = torch.LongTensor(y_val_np)\n",
    "y_test_tensor = torch.LongTensor(y_test_np)\n",
    "X_train_tensor = torch.LongTensor(X_train_padded)\n",
    "X_val_tensor = torch.LongTensor(X_val_padded)\n",
    "X_test_tensor = torch.LongTensor(X_test_padded)\n",
    "# Define a custom dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: torch.Size([64, 20])\n",
      "Labels shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = TextDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TextDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TextDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Test the data loaders\n",
    "for batch in train_loader:\n",
    "    inputs, labels = batch\n",
    "    print(\"Inputs shape:\", inputs.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "    break  # Print the first batch only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleRNN(\n",
      "  (embedding): Embedding(461951, 128)\n",
      "  (rnn): RNN(128, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        # Take the hidden state from the last time step\n",
    "        hidden = hidden.squeeze(0)\n",
    "        output = self.fc(hidden)\n",
    "        return output\n",
    "\n",
    "# Define the input size, hidden size, and output size\n",
    "input_size = vocabulary_size \n",
    "hidden_size = 128\n",
    "output_size = 2  # Assuming binary classification\n",
    "\n",
    "# Create the model instance\n",
    "model = SimpleRNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.1341\n",
      "Epoch [2/10], Loss: 0.1147\n",
      "Epoch [3/10], Loss: 0.1084\n",
      "Epoch [4/10], Loss: 0.1046\n",
      "Epoch [5/10], Loss: 0.1010\n",
      "Epoch [6/10], Loss: 0.0979\n",
      "Epoch [7/10], Loss: 0.0949\n",
      "Epoch [8/10], Loss: 0.0915\n",
      "Epoch [9/10], Loss: 0.0886\n",
      "Epoch [10/10], Loss: 0.0860\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "# Define hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Iterate over the training data\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Calculate average loss for the epoch\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    # Print training loss for the epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}')\n",
    "\n",
    "print('Training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define function for testing\n",
    "def test_model(model, test_loader, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to device\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = correct / total\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "    return accuracy, f1\n",
    "\n",
    "# Test the model\n",
    "test_accuracy, test_f1 = test_model(model, test_loader, criterion)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2%}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch():\n",
    "\n",
    "    model.train(False)\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    for i, data in enumerate(test_loader):\n",
    "        input, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input) # shape: [batch_size, 10]\n",
    "            _,predicted = torch.max(outputs,1)\n",
    "            correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "            running_accuracy += correct / batch_size\n",
    "            loss = criterion(outputs, labels) # One number, the average batch loss\n",
    "            running_loss += loss.item()\n",
    "            predictions.extend(predicted.cpu().numpy())  # Move predictions back to CPU\n",
    "            true_labels.extend(labels.cpu().numpy())  # Move true labels back to CPU\n",
    "\n",
    "    avg_loss_across_batches = running_loss / len(test_loader)\n",
    "    avg_acc_across_batches = (running_accuracy / len(test_loader)) * 100\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    print('test Loss: {0:.5f}, test Accuracy: {1:.3f}%'.format(avg_loss_across_batches,\n",
    "                                                            avg_acc_across_batches))\n",
    "    print('***************************************************')\n",
    "    print()\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    return avg_loss_across_batches,avg_acc_across_batches\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.33263, test Accuracy: 92.592%\n",
      "***************************************************\n",
      "\n",
      "F1 Score: 0.9079\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = test_one_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the file path to save the model\n",
    "model_path = 'model.pkl'\n",
    "\n",
    "# Move the model to CPU\n",
    "model_cpu = model.to('cpu')\n",
    "\n",
    "# Serialize and save the model\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(model_cpu, f)\n",
    "\n",
    "# # Load the model from file\n",
    "# with open(model_path, 'rb') as f:\n",
    "#     loaded_model = pickle.load(f)\n",
    "\n",
    "# # Ensure the model is on the correct device (e.g., GPU)\n",
    "# loaded_model = loaded_model.to(device)\n",
    "\n",
    "# # Set the model to evaluation mode\n",
    "# loaded_model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
